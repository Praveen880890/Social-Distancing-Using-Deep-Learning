{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple OpenVINO Optimized YOLOv8 Inferencing Demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the previously prepared OpenVINO optimized YOLOv8 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "core = Core()\n",
    "# Load the pre optimized model\n",
    "yolov8n_with_preprocess_model = core.read_model('../models/yolov8n_openvino_int8_model/yolov8n_with_preprocess.xml',)\n",
    "\n",
    "\n",
    "import json\n",
    "# Load the label map\n",
    "with open('../models/yolov8n_labels.json', 'r') as f:\n",
    "    label_map = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "Setup the live player for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from IPython import display\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import Dict, Tuple\n",
    "from ultralytics.yolo.utils.plotting import colors\n",
    "from utils import VideoPlayer, detect_without_preprocess\n",
    "\n",
    "distance_thres=100\n",
    "\n",
    "def draw_results_new(results:Dict, source_image:np.ndarray, label_map:Dict):\n",
    "    \"\"\"\n",
    "    Helper function for drawing bounding boxes on image\n",
    "    Parameters:\n",
    "        image_res (np.ndarray): detection predictions in format [x1, y1, x2, y2, score, label_id]\n",
    "        source_image (np.ndarray): input image for drawing\n",
    "        label_map; (Dict[int, str]): label_id to class name mapping\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    boxes = results[\"det\"]\n",
    "    masks = results.get(\"segment\")\n",
    "    h, w = source_image.shape[:2]\n",
    "    # print(\"####\",type(boxes.item()))\n",
    "    boxes=[t.numpy() for t in boxes]\n",
    "    persons = []\n",
    "    person_centres = []\n",
    "    violate = set()\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "            label = label_map[str(int(boxes[i][-1]))]\n",
    "            if label==\"person\":\n",
    "                x,y,w,h = tuple(boxes[i][:4])\n",
    "                persons.append(tuple(boxes[i][:4]))\n",
    "                person_centres.append([x+w//2,y+h//2])\n",
    "    # print(\"##\",len(persons))\n",
    "    # print(\"$%%%\",len(person_centres))\n",
    "    for i in range(len(persons)):\n",
    "         for j in range(i+1,len(persons)):\n",
    "                if dist(person_centres[i],person_centres[j]) <= distance_thres:\n",
    "                    violate.add(tuple(persons[i]))\n",
    "                    violate.add(tuple(persons[j]))\n",
    "    v = 0\n",
    "    for (x,y,w,h) in persons:\n",
    "        if (x,y,w,h) in violate:\n",
    "                color = (0,0,225)\n",
    "                v+=1\n",
    "        else:\n",
    "                    \n",
    "                color = (125,255,0)\n",
    "    \n",
    "        \n",
    "        tl = 1 or round(0.002 * (source_img.shape[0] + source_image.shape[1]) / 2) + 1  # line/font thickness\n",
    "        color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "        cv2.rectangle(source_image,(int(x),int(y)),(int(w),int(h)),color,thickness=tl, lineType=cv2.LINE_AA)\n",
    "        c1,c2=(int(x),int(y)),(int(w),int(h))\n",
    "        if label==\"person\":\n",
    "            tf = max(tl - 1, 1)  # font thickness\n",
    "            t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "            \n",
    "            c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "            cv2.rectangle(source_image, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "            cv2.putText(source_image, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "        \n",
    "    cv2.putText(source_image,'Number of Violations : '+str(v),(80,source_image.shape[0]-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "    return source_image\n",
    "# Caluculate the euclidean distance\n",
    "def dist(pt1,pt2):\n",
    "    try:\n",
    "        return ((pt1[0]-pt2[0])**2 + (pt1[1]-pt2[1])**2)**0.5\n",
    "    except:\n",
    "        return\n",
    "        \n",
    "# Run the object detection\n",
    "def run_object_detection(source=0, flip=False, use_popup=False, skip_first_frames=0, model=\"None\", device=\"None\"):\n",
    "    player = None\n",
    "    # if device != \"CPU\":\n",
    "    #     model.reshape({0: [1, 3, 640, 640]})\n",
    "    compiled_model = core.compile_model(model, device)\n",
    "    try:\n",
    "        # Create a video player to play with target fps.\n",
    "        player = VideoPlayer(\n",
    "            source=source, flip=flip, fps=30, skip_first_frames=skip_first_frames\n",
    "        )\n",
    "        \n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "        out = cv2.VideoWriter('../demo_videos/output.mp4', fourcc, 20.0, (1280,720))\n",
    "        # Start capturing.\n",
    "        player.start()\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit\"\n",
    "            cv2.namedWindow(\n",
    "                winname=title, flags=cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE\n",
    "            )\n",
    "\n",
    "        processing_times = collections.deque()\n",
    "        while True:\n",
    "            # Grab the frame.\n",
    "            frame = player.next()\n",
    "            if frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "            # If the frame is larger than full HD, reduce size to improve the performance.\n",
    "            scale = 1280 / max(frame.shape)\n",
    "            if scale < 1:\n",
    "                frame = cv2.resize(\n",
    "                    src=frame,\n",
    "                    dsize=None,\n",
    "                    fx=scale,\n",
    "                    fy=scale,\n",
    "                    interpolation=cv2.INTER_AREA,\n",
    "                )\n",
    "            # Get the results.\n",
    "            input_image = np.array(frame)\n",
    "           \n",
    "            start_time = time.time()\n",
    "            # model expects RGB image, while video capturing in BGR\n",
    "            detections = detect_without_preprocess(input_image, compiled_model)[0]\n",
    "            stop_time = time.time()\n",
    "            \n",
    "            image_with_boxes = draw_results_new(detections, input_image, label_map)\n",
    "            frame = image_with_boxes\n",
    "                \n",
    "            processing_times.append(stop_time - start_time)\n",
    "            # Use processing times from last 200 frames.\n",
    "            if len(processing_times) > 200:\n",
    "                processing_times.popleft()\n",
    "            _, f_width = frame.shape[:2]\n",
    "            # Mean processing time [ms].\n",
    "            processing_time = np.mean(processing_times) * 1000\n",
    "            fps = 1000 / processing_time\n",
    "            cv2.putText(\n",
    "                img=frame,\n",
    "                text=f\"Inference time: {processing_time:.1f}ms ({fps:.1f} FPS)\",\n",
    "                org=(20, 40),\n",
    "                fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "                fontScale=f_width / 900,\n",
    "                color=(0, 0, 255),\n",
    "                thickness=3,\n",
    "                lineType=cv2.LINE_AA,\n",
    "            )\n",
    "            \n",
    "            # Use this workaround if there is flickering.\n",
    "            if use_popup:\n",
    "                cv2.imshow(winname=title, mat=frame)\n",
    "                out.write(frame)\n",
    "               \n",
    "                key = cv2.waitKey(1)\n",
    "                # escape = 27\n",
    "                if key == 27:\n",
    "                    break\n",
    "                \n",
    "            else:\n",
    "                # Encode numpy array to jpg.\n",
    "                _, encoded_img = cv2.imencode(\n",
    "                    ext=\".jpg\", img=frame, params=[cv2.IMWRITE_JPEG_QUALITY, 100]\n",
    "                )\n",
    "                # Create an IPython image.\n",
    "                i = display.Image(data=encoded_img)\n",
    "                # Display the image in this notebook.\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(i)\n",
    "                key = cv2.waitKey(1)\n",
    "            if key==ord(\"q\"):\n",
    "                \n",
    "                break\n",
    "    # ctrl-c\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    # any different error\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if player is not None:\n",
    "            # Stop capturing.\n",
    "            player.stop()\n",
    "        if use_popup:\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the video feed and run the object detection\n",
    "run_object_detection(source=\"../data/pedestrians.mp4\", flip=False, use_popup=True,skip_first_frames=0, model=yolov8n_with_preprocess_model, device=\"AUTO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
